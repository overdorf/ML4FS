{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HW 3: Data Visualisation \n",
    "\n",
    "## Introduction\n",
    "You probably already have some knowledge in data visualization that you may have acquired in other dedicated courses. The purpose of this assignment is not to teach you all aspects of data visualization and the associated challenges.  The goal is that by the end of this homework, you will be able to generate visualizations of your data useful when working with machine learning algorithms. There are three aspects you want to visualize: before starting you need to have an idea of your data in general, and of your labels in particular. After having deployed your machine learning you need to be able to visualize the results of f.ex. classifier. \n",
    "\n",
    "This HW does not replace the visualization tools you already know, but it will allow you to create visualizations to understand your data or evaluate your results without having to export your data and import it into your favorite software and go back and forth every time you make a change. Using libraries such as Matplotlib and Seaborn, you'll be able to create a variety of plots, including histograms, scatter plots, confusion matrix, and more. These visualizations will enable you to gain valuable insights from your data and classifiers/regressor.\n",
    "\n",
    "This HW focuses on a few visualizations libraries for Python. You will see how these tools can be used to quickly explore your data, understand their structure, and effectively evaluate your results.\n",
    "\n",
    "For the sake of colorblind-people, you can create your custom signature color-palettes:\n",
    "- [coolors](https://coolors.co/)\n",
    "And then check [here](https://davidmathlogic.com/colorblind/#%23D81B60-%231E88E5-%23FFC107-%23004D40) to get a \"feeling\" of how colorblind people would see your palette. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a5f999e732a762a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Setting-up environment \n",
    "As always, the first step is making sure your environment is ready. Like you learned in previous HWs, the best practice is to have a virtual environment, either one per HW or one for the ML course. Once you have it, you can try to import the follow modules:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "134f92445c54ac5f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import section\n",
    "\n",
    "# This is a very important library, which allow you to handle file path on macOS and Windows almost flawlessly \n",
    "# No more problem of / VS \\ or use of the \\\\. You juste use Path(r\"some_path\"). The good practice is to use forward slash as it will work everywhere, but with the r at the start of the string, you should be fine with anything\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# The last line allow to show matplotlib graph in an easier way in the notebook\n",
    "# It is juste an argument given to the matplotlib module"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d998b28160b79673"
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you have an error, try to install the module(s) with the following line:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e170adb6f05b810"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!pip install <module_name>\n",
    "!pip install seaborn"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59c515b988f3af0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 1: Visualize data from HW1\n",
    "\n",
    "For this first part, we will use a part of the dataset you used on the previous homework and do some easy and not-so-easy visualisation with it. \n",
    "\n",
    "### 1.1 Loading the data\n",
    "\n",
    "Just as you saw last week, load the data to a DataFrame object, using any ways you prefer. (We proposed a way, feel free to change it :))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af4eb99da50a2239"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_folder = Path('./data/')\n",
    "\n",
    "df_ex1 = pd.read_csv(data_folder / \"logging_data_merged.csv\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9c2779906f239c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2: Explore the data\n",
    "\n",
    "You already did that last week so no need to do it again ;). But if you want, feel free to add some insights of the data here :)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaa570f1f090f26e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9ac95bc8cc253c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 Pre-processing data\n",
    "\n",
    "Here you can add steps needed to transform your data the way it needs to be, like changing timestamp_readable to datetime for example :)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c354e17b3f28fdd8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "813d27f7023f391b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 First plots, junior edition\n",
    "\n",
    "*Visualizing a single variable: histogram*\n",
    "\n",
    "There is almost an infinite ways of visualizing data in Python. Here you will see the basic ones to visualize one variable, using most comon libraries. The first thing we can do with ou data is to make histogram of some variables. The easiest way is to use a built-in pandas feature called hist()."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1604674eb11dee9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Here we plot the number of access per room number:\n",
    "number_of_rooms = len(df_ex1[\"room\"].unique())\n",
    "df_ex1[\"room\"].hist(bins=number_of_rooms)\n",
    "\n",
    "# By changing the column name, you change the column that is plotted.\n",
    "# The first line is here to compute how many bars we want on our graph. You can try to run it with bins=5 for exemple to see the difference."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32a7d5ef374990d2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This graph is nice, but as you should know, it is missing some key elements to be a \"correct\" graph. To add elements of context, we can use the following element:\n",
    "- plt.xlabel()\n",
    "- plt.ylabel()\n",
    "- plt.title() \n",
    "\n",
    "But for this, we need to import matplotlib (you already did it in the beginning of this HW). This allows to specify the title and the axis' names. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f972380cc4ecb511"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# You can use the pandas features\n",
    "df_ex1[\"room\"].hist(bins=number_of_rooms)\n",
    "\n",
    "# Or directly matplotlib, either will work the same, with some aesthetic differences\n",
    "#plt.hist(df[\"room\"].values, bins=number_of_rooms)\n",
    "\n",
    "# You can play with plt attribute to customize your graph, like color, legend for example\n",
    "plt.xlabel('Room number')\n",
    "plt.ylabel('Number of access')\n",
    "plt.title('Rooms access - Histogram');"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "279331e161266866"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question**\n",
    "Does the graph looks like you were expecting? Can you tell if it was a good idea to plot it like that?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee5373530db9f3ff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Your response here_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed1ac976e44cf985"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, try to plot the distribution of the access by floor, and not by rooms"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b702114ae01abcf8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2f9f789bc9c0419"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question**\n",
    "Can you interpret it differently than the last one?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e43bbd550dc389ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Your response here_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eacb814e4ecfc2ff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Visualizing a single variable: boxplot* \n",
    "\n",
    "Another way to plot the distribution of one variable is to use boxplot. This is especially useful to see outliers in your data. This can allow you to errors in records. For example, we can plot the timestamp of the rooms' access, using the following code:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db64ab190bd2aee2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.boxplot(df_ex1['timestamp'])\n",
    "# Removing the label on the x-axis\n",
    "plt.xticks([])\n",
    "plt.title('Timestamps')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca2944d2e6b4804c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question**\n",
    "Do you see a problem with this graph? Can you conclude something on your data?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d324a828237ecbb2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Your response here_\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b63d72e76e220277"
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you detect some big outliers (I hope you did ;)) can you try to explain them?\n",
    "As we have two fields storing the timestamp information (timestamp and timestamp_readable) you should see if the error you detect in the timestamp is replicated in the timestamp_readable. Maybe it is juste a conversion or parsing error :)\n",
    "\n",
    "Before plotting timestamp_readable, you should have converted it to datetime object in the previous steps. If you don't do so, the boxplot will have no meaning as it will only plot strings, with no real distribution analysis. \n",
    "Moreover, pandas matplotlib can't easily do boxplot of datetime object, so we will introduce a more advanced module: seaborn. It has most of the same features as matplotlib, but include some more advanced and easy-use ones. The syntax is basically the same, by replacing plt by sns: sns.boxplot(df[\"column_name\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "912cbc6d2bfee5ce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e2316227189bd0c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question**\n",
    "Do you notice any difference with the boxplot of the column _timestamp_?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d6952de3ffabff7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Your response here_\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e4d5b9d76d64095"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 Stepping up: comparing two variables\n",
    "\n",
    "You certainly noticed a difference in the distribution of timestamp and timestamp_readable, although they should represent the same information, just in a different format. We will see a way to plot two variable, one per axis. It allows to compare the variation of the two variables. As the two variables should exactly be the same, we are expecting them to lay on the line y=x.\n",
    "Reference: [Scatter plot in pandas](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.scatter.html)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "238e369284905b0e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1dd12a3322bc3a9f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we can get back to our visualisation of rooms and floors. Before, we did two histograms, one for each variable. But what if we want to compare those two distributions? We will show you two ways of doing that: the joint-plot and \"violin\" plot of seaborn and the classic heatmap:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bbdf8a246392228"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.5.1: Joint-plot\n",
    "You can try to play with the kind= parameter to get other type of visualisation in the plot. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10493c724a2e83be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The seaborn way (easy, aesthetic but not very precise)\n",
    "sns.jointplot(x=df_ex1['room'], y=df_ex1['floor'], kind=\"hex\", gridsize=len(df_ex1['floor'].unique())*2-2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57bcc21c776a03fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.5.2: Violin-plot"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd6d42d280e4550b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Another way to compare two variables (suppose to look like VIOLIN...)\n",
    "sns.violinplot(df_ex1, x='floor', y='room')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "671bcac3f1e1652d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5.3: Heatmap\n",
    "\n",
    "To do a heatmap in Python, the most common way is to build a new dataframe containing the heatmap data, and then visualize it as an heatmap"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c468c0264cea2a78"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# To do the heatmap, we have to build it ourselves\n",
    "# First, we do a value_counts to have a df with the door number as index, and the count as value\n",
    "heatmap_df = df_ex1[\"door\"].value_counts()\n",
    "# Then we reset the index to make a \"2 columns\" dataframe (door and count)\n",
    "heatmap_df = heatmap_df.reset_index()\n",
    "# Then we split the door column into two columns, the floor and the room\n",
    "heatmap_df['floor'] = heatmap_df['door'].apply(lambda string: int(string.split('-')[0]))\n",
    "heatmap_df['room'] = heatmap_df['door'].apply(lambda string: int(string.split('-')[-1]))\n",
    "\n",
    "# We drop the column door because we don't need it anymore\n",
    "heatmap_df.drop('door', axis=1, inplace=True)\n",
    "\n",
    "# We do a pivot to get the floors as indexes (y-axis) and the rooms as column names (x-axis)\n",
    "heatmap_df = heatmap_df.pivot(columns='room',index='floor',values='count')\n",
    "# We sort the index so that the floor 0 is at the bottom of the graph\n",
    "heatmap_df.sort_index(ascending=False, inplace=True)\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(15, 5)) # choosing the size of the graph (not too small\n",
    "sns.heatmap(heatmap_df, annot=True)\n",
    "# Using a function that make the graph it better, you can try with and without it to see what suits you the best\n",
    "plt.tight_layout() \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a58708a04977a9e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question**\n",
    "Can you try it to make a function that take as argument a dataframe, two columns and show a heatmap (you can help you with the above code?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c27166bf2c98bee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37c4e87abfb3cf4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Bonus Question**\n",
    "With those three visualizations, what can you say about the layout of the building? And what hypothesis can you make about the habits of the employees?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78f0249dd3ea9bed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Your response here_\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "392bda5ede0417d5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 2: Monitoring of Federal Criminal Sentences\n",
    "\n",
    "For this exercise, you will have data containing a multitude of information concerning criminal sentences in the US ([source](https://www.icpsr.umich.edu/web/NACJD/studies/37975/versions/V1#)). The goal of this exercise is to gain insights of this data through visualisation(s)\n",
    "\n",
    "### 2.1 Load the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "216b571e615051cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_folder_ex2 = Path(r\"data/Criminal_sentences/data\")\n",
    "\n",
    "# sep= parameter specifies what character is used to separate columns\n",
    "df_ex2 = pd.read_csv(data_folder_ex2 / \"0001-Data_with_predictions.tsv\", sep=\"\\t\")\n",
    "df_ex2.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e1f8e4816d4b0b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Explore the data\n",
    "\n",
    "Use what you learned last week (and maybe more) to get a first understanding of the data. For example, can you tell what are the datatypes, the principal statistic characteristics, and so on? If you need (I hope you don't) but you can read the Codebook.pdf to see the column's list and the documentation. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7553a34b95dbf7e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Small hint: the describe() method can be useful\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aff2383c54d0ca4c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you should have noticed, there is a LOT of columns in those data. We will use the following columns:\n",
    "- AGE - Age of the defendant\n",
    "- DOBMON - DEFENDANT'S MONTH OF BIRTH\n",
    "- MONSEX - DEFENDANT'S GENDER\n",
    "- SENTTOT - TOTAL PRISON SENTENCE IN MONTHS WITHOUT ZEROS\n",
    "- SENTMON - MONTH OF SENTENCING\n",
    "- FINE - DOLLAR AMOUNT OF FINE ORDERED\n",
    "- SENTTOT_PREDICT1 - SENTENCE PREDICTED BY AN ALGORITHM\n",
    "- SENTTOT_PREDICT2 - SENTENCE PREDICTED BY AN ALGORITHM\n",
    "- SENTTOT_PREDICT3 - SENTENCE PREDICTED BY AN ALGORITHM\n",
    "\n",
    "Three predictions where made with different algorithms. We will look at it in this exercise.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe0cf1cd95c35bda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Preprocess data\n",
    "\n",
    "Here you should handle the dtype of your data and also handle the missing / null value. \n",
    "\n",
    "One thing you MUST do for the sake of this exercise, is handling missing data in the needed column (missing data are a string with a space, in case you didn't read the Codebook.pdf ;))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3d38427a360c9ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f85b06149c70987"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# extracting a subset with only the columns that we're going to use (the one listed above, without the predict ones)\n",
    "# create a variable column_names with the names pertinent columns\n",
    "df_ex2_subset = df_ex2[column_names]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b8b43e08399e4ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 Plots the data, senior edition\n",
    "First let's see if you are really a senior visualist :)\n",
    "Make a histogram of the AGE variable"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a51d60dff1085663"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "890da5daa11e78d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.4.2 Log axes\n",
    "Make a scatter plot of the FINE variables and the AGE variable"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18c7da8be5d7140d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2823e34627a07db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you should have seen, there is a lot of data points near the x-axis. Now you can try to plot it on a log y-axis and see the difference"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71f1beae9e820712"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8602c3f7c132c0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question**\n",
    "Do you see a problem with this visualisation? Do you think of another visualisation that would allow you to get some other insights about the data?  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bb1b688fb33dc73"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.4.3: Correlation visualisation (not quite analysis yet, wait for next week :))\n",
    "\n",
    "You already saw a way to visualise correlation in the first exercise, where you plotted the two timestamp related column in one scatter plot. Now you will see how to do it wth multiple of variable at the same time, instead of doing it one by one.\n",
    "\n",
    "A somewhat convenient way to visualize the correlation between a lot of variable (comparing each variable with each other variable, two by two) is to use pair-plots from sns. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dcec52a792afac9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# you can play with the kind= parameter to see the different output that it gives you (the execution might take some time on you laptop, like 3-4 minutes... So maybe duplicate this cell and run it with the different parameter values, so you can keep the 4 results in your notebook :)\n",
    "# value that you can try are: ‘scatter’, ‘kde’, ‘hist’, ‘reg’\n",
    "sns.pairplot(df_ex2_subset, kind='scatter')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "869494ff29cf4f4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question**\n",
    "What are the main differences with the different parameter you tried? Is there one or more that you wouldn't advise to use in this case? And if yes, why?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3757d66b6971a84"
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Your response here_\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a0639000510d58a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This gave you a way to conclude a visual analysis of the correlation between variable, but most of the time it is really hard to do it like that. Especially next week, you will need to get more numerical value, so we already show you how to get the same grid as before, but with the correlation value, instead of graph :)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c80bd65e83197a3b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ex2_corr = df_ex2_subset.corr()\n",
    "df_ex2_corr"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0d12a2f93eafdd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "A table is already a sort of visualisation, but as you're a senior visualist, try to do a heatmap with the correlation :) results. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ce299dc2d210951"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbe065dd20247dad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Question**\n",
    "Short break to breathe and look outside :) we will get to this next week (with different data) ;)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a950f01d1c1146d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4.4 Regression plot\n",
    "\n",
    "With the previous visualization, you certainly noticed that some variables seem to be correlated. You can see this interaction by plotting a regression plot. It uses linear regression, that the course didn't cover yet, so you'll need to wait a little bit for the technical explanation if you don't quiet understand everything it's doing.\n",
    "Reference : [Correlation metric](https://pandas.pydata.org/docs/reference/api/pandas.Series.corr.html) and [plotting](https://seaborn.pydata.org/generated/seaborn.regplot.html). BE WARNED: correlation is not causation...\n",
    "\n",
    "So now take your original data again and extract a new subset containing following column: \n",
    "- SENTTOT\n",
    "- SENTTOT_PREDICT1\n",
    "- SENTTOT_PREDICT2\n",
    "- SENTTOT_PREDICT3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "885d74b85537e24a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "df_ex2_subset_senttot = "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91c1be3cb67aa5dc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we make a correlation graph:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2dfb472a862b3263"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r_squared = df_ex2_subset_senttot['AGE'].corr(df_ex2_subset['SENTTOT']) ** 2\n",
    "\n",
    "sns.regplot(df_ex2_subset_senttot, x='AGE', y='SENTTOT', line_kws={'color': 'red', 'label': f'R-squared = {r_squared}'})\n",
    "plt.legend()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "id": "af5db47c15812701"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The previous graph is useful to visualise how a model predict a quantitative variable. You can play with the columns SENTTOT_PREDICTX to see which of the three models matches the best with SENTTOT column. \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5504c6037f5bffb8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16c3dc8e538707df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 3: Confusion matrices / Visualizing Errors in Classification\n",
    "\n",
    "Confusion Matrices, sometimes called error matrices, visualize the kinds of errors your machine learning algorithm makes.\n",
    "You might know the confusion matrix for binary classifications (cf. Table 1).\n",
    "\n",
    "|                      | **Predicted_Label_True** | **Predicted_Label_False** |\n",
    "|----------------------|--------------------------|---------------------------|\n",
    "| **True_Label_True**  | True Positive            | False Negative            |\n",
    "| **True_Label_False** | False Positive           | True Negative             |\n",
    "_Table 1: Confusion Matrix for binary Classification tasks._\n",
    "\n",
    "If you have multiple classes, the confusion matrix not only indicates what kind of error the classification commits but also helps indicate which classes get confused. This helps identify biases or indicate potential problems in the dataset.\n",
    "\n",
    "For this exercise, imagine you are trying to classify the native language of the author of a given text. You know the native language of the author is either English ('en'), German ('de'), French ('fr'), Spanish ('es') or Portuguese ('pt'). Those are your 5 classes. The file that you can find in the \"language_predictions\" foldr are the result of 4 classifiers you tried. One column contains the real value of the language (ground-truth data) and the other contains the value that was predicted by the classifiers. \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42dce67e44d7f894"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Load the data\n",
    "\n",
    "Load the first file \"prediction_0.csv\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37dac1bf76b2a78"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "df_pred_0 = "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30e4ff5349b748d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2: Visualize a classification\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9d64d6e490a8a98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Make a confusion matrix using sns\n",
    "#Link to documentation: https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
    "#Step 0: Transform the data into the right shape\n",
    "#You need to have a table where the y_true is the index and y_predicted is the column, the number of occurrences of a given combination needs to be the data\n",
    "#Lookup pd.pivot_table \n",
    "df_matrix= df_pred_0.groupby(['Y_true','Y_predicted']).size() #This counts the number of occurrences of a combination of labels\n",
    "df_matrix= df_matrix.to_frame(name = 'size').reset_index() #This creates a dataframe\n",
    "df_matrix= pd.pivot(df_matrix, values='size', columns='Y_predicted', index='Y_true')#This puts everything into the correct form\n",
    "#Step 1: Heatmap\n",
    "sns.heatmap(df_matrix, annot=True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a95a819d60727f17"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Normally, you should realize that this classifier is wonderful (certainly too good to be true, sadly). Can you explain how did you notice that it was a \"perfect\" classifier?\n",
    "\n",
    "What yould be a reason for having achieved 100% accuracy?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8710d944fa6a23a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3: Comparing different classifier\n",
    "\n",
    "Now that you have make your first confusion matrices (in this course nonetheless), you can create confusion matrices for the 3 other classifiers, and try to evaluate them. We didn't show you how to compute the accuracy of a classifier (yet) so try to evaluate them just by using the confusion matrices :)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d00339071bb5b14a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 4: Work on your project :)\n",
    "\n",
    "If you already have data for your project, do not hesitate to start doing some exploration by visualizing your data (maybe in another notebook to make you life easier, but you do you ;))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "387c4996354e0361"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "96be4f45f8f1f375"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "93a48298b3bd5a9f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f1bc30ce8de3476f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "72e2ef700cc40830"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bf7e5a8a21ab9b15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b98666767ed4b911"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a0cf86118bd98730"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3494be388ffec700"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "95ceaf5aad6821ed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
